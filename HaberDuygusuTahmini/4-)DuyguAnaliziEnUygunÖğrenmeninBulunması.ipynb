{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haber Tahmini İçin En Uygun Makine Öğrenmesi Algoritmasının Bulunması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anakonda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from sklearn import model_selection, preprocessing ,linear_model,naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer ,CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas ,xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evi Terk Eden Eşi Sevgililer Günü’nde Barışmay...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeliz Koray’ın 6 Yıldır Terör Örgütünün Elinde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geçim Sıkıntısı Çeken Anne ve Baba, Çocukların...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Türk Denizciyle Hırvat Sevgilisinin Filmlere T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>İtalya'daki Türk Öğrencinin Bursuyla Yaptığı M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17203</th>\n",
       "      <td>Kitaplara Göre Yapılmış 17 Karakter Analizi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17204</th>\n",
       "      <td>Final Sınavlarına Mizahıyla İsyan Eden 18 Kişi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17205</th>\n",
       "      <td>Alakasız Sohbetler Kanalından Eğlendirirken Öğ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17206</th>\n",
       "      <td>Bir Uçakta Yaşanmış \"Oldu Olacak Deve Getirsey...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17207</th>\n",
       "      <td>Vahşi Batı'nın Yenilmez Kovboyu Red Kit'i Sevm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17208 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Sentiment\n",
       "0      Evi Terk Eden Eşi Sevgililer Günü’nde Barışmay...          0\n",
       "1      Yeliz Koray’ın 6 Yıldır Terör Örgütünün Elinde...          0\n",
       "2      Geçim Sıkıntısı Çeken Anne ve Baba, Çocukların...          0\n",
       "3      Türk Denizciyle Hırvat Sevgilisinin Filmlere T...          0\n",
       "4      İtalya'daki Türk Öğrencinin Bursuyla Yaptığı M...          0\n",
       "...                                                  ...        ...\n",
       "17203        Kitaplara Göre Yapılmış 17 Karakter Analizi          1\n",
       "17204     Final Sınavlarına Mizahıyla İsyan Eden 18 Kişi          1\n",
       "17205  Alakasız Sohbetler Kanalından Eğlendirirken Öğ...          1\n",
       "17206  Bir Uçakta Yaşanmış \"Oldu Olacak Deve Getirsey...          1\n",
       "17207  Vahşi Batı'nın Yenilmez Kovboyu Red Kit'i Sevm...          1\n",
       "\n",
       "[17208 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #Verileri okumak\n",
    "data1 = pd.read_csv('onedioÇokAcı.csv')\n",
    "data2 = pd.read_csv('onedioKızgın2.csv')\n",
    "data3 = pd.read_csv('thegeyikHayvanlar.csv')\n",
    "data4 = pd.read_csv('thegeyikKomik.csv')\n",
    "data5 = pd.read_csv('thegeyikSeyehat.csv')\n",
    "data6 = pd.read_csv('onedioGoygoy.csv')\n",
    "data7 = pd.read_csv('onedioGoygoy2.csv')\n",
    "data=pd.concat([data1,data2,data3,data4,data5,data6,data7], ignore_index = True) #Verileri birleştirmek\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analizi Ve Sınıflandırma Modelleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentiment\"].replace(0,value = \"negatif\" ,inplace = True) #0 lara negatif \n",
    "data[\"Sentiment\"].replace(1,value = \"pozitif\" ,inplace = True) #1 lere pozitif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evi Terk Eden Eşi Sevgililer Günü’nde Barışmay...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeliz Koray’ın 6 Yıldır Terör Örgütünün Elinde...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geçim Sıkıntısı Çeken Anne ve Baba, Çocukların...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Türk Denizciyle Hırvat Sevgilisinin Filmlere T...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>İtalya'daki Türk Öğrencinin Bursuyla Yaptığı M...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17203</th>\n",
       "      <td>Kitaplara Göre Yapılmış 17 Karakter Analizi</td>\n",
       "      <td>pozitif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17204</th>\n",
       "      <td>Final Sınavlarına Mizahıyla İsyan Eden 18 Kişi</td>\n",
       "      <td>pozitif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17205</th>\n",
       "      <td>Alakasız Sohbetler Kanalından Eğlendirirken Öğ...</td>\n",
       "      <td>pozitif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17206</th>\n",
       "      <td>Bir Uçakta Yaşanmış \"Oldu Olacak Deve Getirsey...</td>\n",
       "      <td>pozitif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17207</th>\n",
       "      <td>Vahşi Batı'nın Yenilmez Kovboyu Red Kit'i Sevm...</td>\n",
       "      <td>pozitif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17208 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Sentiment\n",
       "0      Evi Terk Eden Eşi Sevgililer Günü’nde Barışmay...   negatif\n",
       "1      Yeliz Koray’ın 6 Yıldır Terör Örgütünün Elinde...   negatif\n",
       "2      Geçim Sıkıntısı Çeken Anne ve Baba, Çocukların...   negatif\n",
       "3      Türk Denizciyle Hırvat Sevgilisinin Filmlere T...   negatif\n",
       "4      İtalya'daki Türk Öğrencinin Bursuyla Yaptığı M...   negatif\n",
       "...                                                  ...       ...\n",
       "17203        Kitaplara Göre Yapılmış 17 Karakter Analizi   pozitif\n",
       "17204     Final Sınavlarına Mizahıyla İsyan Eden 18 Kişi   pozitif\n",
       "17205  Alakasız Sohbetler Kanalından Eğlendirirken Öğ...   pozitif\n",
       "17206  Bir Uçakta Yaşanmış \"Oldu Olacak Deve Getirsey...   pozitif\n",
       "17207  Vahşi Batı'nın Yenilmez Kovboyu Red Kit'i Sevm...   pozitif\n",
       "\n",
       "[17208 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negatif</th>\n",
       "      <td>5694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pozitif</th>\n",
       "      <td>11514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Text\n",
       "Sentiment       \n",
       "negatif     5694\n",
       "pozitif    11514"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evi Terk Eden Eşi Sevgililer Günü’nde Barışmay...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeliz Koray’ın 6 Yıldır Terör Örgütünün Elinde...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geçim Sıkıntısı Çeken Anne ve Baba, Çocukların...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Türk Denizciyle Hırvat Sevgilisinin Filmlere T...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>İtalya'daki Türk Öğrencinin Bursuyla Yaptığı M...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  Evi Terk Eden Eşi Sevgililer Günü’nde Barışmay...  negatif\n",
       "1  Yeliz Koray’ın 6 Yıldır Terör Örgütünün Elinde...  negatif\n",
       "2  Geçim Sıkıntısı Çeken Anne ve Baba, Çocukların...  negatif\n",
       "3  Türk Denizciyle Hırvat Sevgilisinin Filmlere T...  negatif\n",
       "4  İtalya'daki Türk Öğrencinin Bursuyla Yaptığı M...  negatif"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame() \n",
    "df[\"text\"] = data[\"Text\"]\n",
    "df[\"label\"] = data [\"Sentiment\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metin Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buyuk-kucuk donusumu\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "#noktalama işaretleri\n",
    "df['text'] = df['text'].str.replace('[^\\w\\s]','')\n",
    "#sayılar\n",
    "df['text'] = df['text'].str.replace('\\d','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bir           2627\n",
       "ve            1873\n",
       "en            1822\n",
       "komik         1821\n",
       "kişi          1737\n",
       "              ... \n",
       "kahvesini        1\n",
       "ödesek           1\n",
       "yaşatarak        1\n",
       "getirtecek       1\n",
       "gelmesini        1\n",
       "Length: 35623, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(\" \".join(df[\"text\"]).split()).value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('Turkish')\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha', 'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani']\n"
     ]
    }
   ],
   "source": [
    "print(sw) #Stopwordsler aslında dildeki sık kullanılan kelimeler bunları veri setimizde istemiyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burada kelime köklerini \n",
    "from snowballstemmer import TurkishStemmer\n",
    "turkStem=TurkishStemmer()\n",
    "#nltk.download('wordnet')\n",
    "from textblob import Word\n",
    " #nltk.download('wordnet')\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join([turkStem.stemWord(word) for word in x.split()])) #kelimelerin köklerine indirgedik. Bu işlem veri işleme için önemli bir adım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seyreklerin silinmesi\n",
    "sil = pd.Series(' '.join(df['text']).split()).value_counts()[-1000:]\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ÖnİşlenmişVeriler2.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Değişken Mühendisliği"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir şekilde metinleri ölcülebilir metriklere dönüştürmek istiyoruz. \n",
    "- Count Vectors: Basit sayma işlemleri\n",
    "- TF-IDF Vectors(words,chracters,n-grams)\n",
    "- TF(t) = (Bir t teriminin bir dökümanda gözlenme frekansı / dökümandaki toplam terim sayısı)\n",
    "- IDF(t) = log_e(Toplam döküman sayısı içinde t terimi olan belge sayısı)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x ,test_x,train_y,test_y = model_selection.train_test_split(df[\"text\"],\n",
    "                                                                 df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count = vectorizer.transform(train_x)\n",
    "X_test_count = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abartmama',\n",
       " 'abartmış',\n",
       " 'abarttık',\n",
       " 'abartı',\n",
       " 'abartıl',\n",
       " 'abartılır',\n",
       " 'abartılıyor',\n",
       " 'abartıp',\n",
       " 'abazoğl',\n",
       " 'abbasoğlu']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[10:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.toarray() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDF-IDF(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_word_vectorizer = TfidfVectorizer()\n",
    "tf_idf_word_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_idf_word = tf_idf_word_vectorizer.transform(train_x)\n",
    "X_test_tf_idf_word = tf_idf_word_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abartmama',\n",
       " 'abartmış',\n",
       " 'abarttık',\n",
       " 'abartı',\n",
       " 'abartıl',\n",
       " 'abartılır',\n",
       " 'abartılıyor',\n",
       " 'abartıp',\n",
       " 'abazoğl',\n",
       " 'abbasoğlu',\n",
       " 'abd',\n",
       " 'abdde',\n",
       " 'abddek',\n",
       " 'abde',\n",
       " 'abdli',\n",
       " 'abdn',\n",
       " 'abdulhamidi',\n",
       " 'abdulkadir',\n",
       " 'abdullah',\n",
       " 'abdurrahma',\n",
       " 'abdye',\n",
       " 'abdülhamidi',\n",
       " 'abdülhamit',\n",
       " 'abdülmeci',\n",
       " 'abi',\n",
       " 'abides',\n",
       " 'abidi',\n",
       " 'abidik',\n",
       " 'abigail',\n",
       " 'abilerdenabla',\n",
       " 'abis',\n",
       " 'abla',\n",
       " 'ablas',\n",
       " 'ablukas',\n",
       " 'abonelik',\n",
       " 'absürdü',\n",
       " 'absürt',\n",
       " 'absürtlük',\n",
       " 'abu',\n",
       " 'abuk']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_word_vectorizer.get_feature_names()[10:50] #içerisindeki verilere bakmak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf_idf_word.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDF-IDF(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(2, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_ngram_vectorizer = TfidfVectorizer(ngram_range=(2,3))\n",
    "tf_idf_ngram_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(train_x)\n",
    "X_test_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDF-IDF(Characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(2, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_chars_vectorizer = TfidfVectorizer(analyzer = \"char\", ngram_range=(2,3))\n",
    "tf_idf_chars_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_idf_chars = tf_idf_chars_vectorizer.transform(train_x)\n",
    "X_test_tf_idf_chars = tf_idf_chars_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makine Öğrenmesi İle Doğruluk Oranlarının Bulunması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors Doğruluk Oranı: 0.8856304969513842\n"
     ]
    }
   ],
   "source": [
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(X_train_count, train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, \n",
    "                                           X_test_count, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Count Vectors Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Doğruluk Oranı: 0.8670420331300923\n"
     ]
    }
   ],
   "source": [
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(X_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, \n",
    "                                           X_test_tf_idf_word, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"TF-IDF Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-GRAM TF-IDF Doğruluk Oranı: 0.7287341498947822\n"
     ]
    }
   ],
   "source": [
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(X_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, \n",
    "                                           X_test_tf_idf_ngram, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"N-GRAM TF-IDF Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARLEVEL Doğruluk Oranı: 0.86169157718664\n"
     ]
    }
   ],
   "source": [
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(X_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, \n",
    "                                           X_test_tf_idf_chars, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"CHARLEVEL Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-Level TF-IDF Doğruluk Oranı: 0.8175298116872606\n"
     ]
    }
   ],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(X_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, \n",
    "                                           X_test_tf_idf_word, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Word-Level TF-IDF Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-GRAM TF-IDF Doğruluk Oranı: 0.7350089030378244\n"
     ]
    }
   ],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(X_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, \n",
    "                                           X_test_tf_idf_ngram, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"N-GRAM TF-IDF Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARLEVEL Doğruluk Oranı: 0.7870814223277397\n"
     ]
    }
   ],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(X_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, \n",
    "                                           X_test_tf_idf_chars, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"CHARLEVEL Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors Doğruluk Oranı: 0.8623876328710949\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, \n",
    "                                           X_test_count, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Count Vectors Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-Level TF-IDF Doğruluk Oranı: 0.8586710192629363\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, \n",
    "                                           X_test_tf_idf_word, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Word-Level TF-IDF Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-GRAM TF-IDF Doğruluk Oranı: 0.7287341498947822\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = loj.fit(X_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, \n",
    "                                           X_test_tf_idf_ngram, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"N-GRAM TF-IDF Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARLEVEL Doğruluk Oranı: 0.86169157718664\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = loj.fit(X_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, \n",
    "                                           X_test_tf_idf_chars, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"CHARLEVEL Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors Doğruluk Oranı: 0.7821923056170075\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(X_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, \n",
    "                                           X_test_count, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Count Vectors Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-Level TF-IDF Doğruluk Oranı: 0.778706091836184\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(X_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, \n",
    "                                           X_test_tf_idf_word, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Word-Level TF-IDF Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARLEVEL Doğruluk Oranı: 0.8207888631090487\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(X_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, \n",
    "                                           X_test_tf_idf_chars, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"CHARLEVEL Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En iyi Doğruluk oranını veren 0.8856304969513842 doğruluk oranı Count Vectors İle LogisticRegression algoritmasında oldu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
